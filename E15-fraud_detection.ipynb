{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 15\n",
    "\n",
    "# Fraud Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "- Fraud Detection Dataset from Microsoft Azure: [data](http://gallery.cortanaintelligence.com/Experiment/8e9fe4e03b8b4c65b9ca947c72b8e463)\n",
    "\n",
    "Fraud detection is one of the earliest industrial applications of data mining and machine learning. Fraud detection is typically handled as a binary classification problem, but the class population is unbalanced because instances of fraud are usually very rare compared to the overall volume of transactions. Moreover, when fraudulent transactions are discovered, the business typically takes measures to block the accounts from transacting to prevent further losses. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accountAge</th>\n",
       "      <th>digitalItemCount</th>\n",
       "      <th>sumPurchaseCount1Day</th>\n",
       "      <th>sumPurchaseAmount1Day</th>\n",
       "      <th>sumPurchaseAmount30Day</th>\n",
       "      <th>paymentBillingPostalCode - LogOddsForClass_0</th>\n",
       "      <th>accountPostalCode - LogOddsForClass_0</th>\n",
       "      <th>paymentBillingState - LogOddsForClass_0</th>\n",
       "      <th>accountState - LogOddsForClass_0</th>\n",
       "      <th>paymentInstrumentAgeInAccount</th>\n",
       "      <th>ipState - LogOddsForClass_0</th>\n",
       "      <th>transactionAmount</th>\n",
       "      <th>transactionAmountUSD</th>\n",
       "      <th>ipPostalCode - LogOddsForClass_0</th>\n",
       "      <th>localHour - LogOddsForClass_0</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>720.25</td>\n",
       "      <td>5.064533</td>\n",
       "      <td>0.421214</td>\n",
       "      <td>1.312186</td>\n",
       "      <td>0.566395</td>\n",
       "      <td>3279.574306</td>\n",
       "      <td>1.218157</td>\n",
       "      <td>599.00</td>\n",
       "      <td>626.164650</td>\n",
       "      <td>1.259543</td>\n",
       "      <td>4.745402</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>62</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1185.44</td>\n",
       "      <td>2530.37</td>\n",
       "      <td>0.538996</td>\n",
       "      <td>0.481838</td>\n",
       "      <td>4.401370</td>\n",
       "      <td>4.500157</td>\n",
       "      <td>61.970139</td>\n",
       "      <td>4.035601</td>\n",
       "      <td>1185.44</td>\n",
       "      <td>1185.440000</td>\n",
       "      <td>3.981118</td>\n",
       "      <td>4.921349</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5.064533</td>\n",
       "      <td>5.096396</td>\n",
       "      <td>3.056357</td>\n",
       "      <td>3.155226</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.314186</td>\n",
       "      <td>32.09</td>\n",
       "      <td>32.090000</td>\n",
       "      <td>5.008490</td>\n",
       "      <td>4.742303</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5.064533</td>\n",
       "      <td>5.096396</td>\n",
       "      <td>3.331154</td>\n",
       "      <td>3.331239</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.529398</td>\n",
       "      <td>133.28</td>\n",
       "      <td>132.729554</td>\n",
       "      <td>1.324925</td>\n",
       "      <td>4.745402</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>132.73</td>\n",
       "      <td>5.412885</td>\n",
       "      <td>0.342945</td>\n",
       "      <td>5.563677</td>\n",
       "      <td>4.086965</td>\n",
       "      <td>0.001389</td>\n",
       "      <td>3.529398</td>\n",
       "      <td>543.66</td>\n",
       "      <td>543.660000</td>\n",
       "      <td>2.693451</td>\n",
       "      <td>4.876771</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   accountAge  digitalItemCount  sumPurchaseCount1Day  sumPurchaseAmount1Day  \\\n",
       "0        2000                 0                     0                   0.00   \n",
       "1          62                 1                     1                1185.44   \n",
       "2        2000                 0                     0                   0.00   \n",
       "3           1                 1                     0                   0.00   \n",
       "4           1                 1                     0                   0.00   \n",
       "\n",
       "   sumPurchaseAmount30Day  paymentBillingPostalCode - LogOddsForClass_0  \\\n",
       "0                  720.25                                      5.064533   \n",
       "1                 2530.37                                      0.538996   \n",
       "2                    0.00                                      5.064533   \n",
       "3                    0.00                                      5.064533   \n",
       "4                  132.73                                      5.412885   \n",
       "\n",
       "   accountPostalCode - LogOddsForClass_0  \\\n",
       "0                               0.421214   \n",
       "1                               0.481838   \n",
       "2                               5.096396   \n",
       "3                               5.096396   \n",
       "4                               0.342945   \n",
       "\n",
       "   paymentBillingState - LogOddsForClass_0  accountState - LogOddsForClass_0  \\\n",
       "0                                 1.312186                          0.566395   \n",
       "1                                 4.401370                          4.500157   \n",
       "2                                 3.056357                          3.155226   \n",
       "3                                 3.331154                          3.331239   \n",
       "4                                 5.563677                          4.086965   \n",
       "\n",
       "   paymentInstrumentAgeInAccount  ipState - LogOddsForClass_0  \\\n",
       "0                    3279.574306                     1.218157   \n",
       "1                      61.970139                     4.035601   \n",
       "2                       0.000000                     3.314186   \n",
       "3                       0.000000                     3.529398   \n",
       "4                       0.001389                     3.529398   \n",
       "\n",
       "   transactionAmount  transactionAmountUSD  ipPostalCode - LogOddsForClass_0  \\\n",
       "0             599.00            626.164650                          1.259543   \n",
       "1            1185.44           1185.440000                          3.981118   \n",
       "2              32.09             32.090000                          5.008490   \n",
       "3             133.28            132.729554                          1.324925   \n",
       "4             543.66            543.660000                          2.693451   \n",
       "\n",
       "   localHour - LogOddsForClass_0  Label  \n",
       "0                       4.745402      0  \n",
       "1                       4.921349      0  \n",
       "2                       4.742303      0  \n",
       "3                       4.745402      0  \n",
       "4                       4.876771      0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "url = 'https://raw.githubusercontent.com/albahnsen/PracticalMachineLearningClass/master/datasets/15_fraud_detection.csv.zip'\n",
    "df = pd.read_csv(url, index_col=0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accountAge</th>\n",
       "      <th>digitalItemCount</th>\n",
       "      <th>sumPurchaseCount1Day</th>\n",
       "      <th>sumPurchaseAmount1Day</th>\n",
       "      <th>sumPurchaseAmount30Day</th>\n",
       "      <th>paymentBillingPostalCode - LogOddsForClass_0</th>\n",
       "      <th>accountPostalCode - LogOddsForClass_0</th>\n",
       "      <th>paymentBillingState - LogOddsForClass_0</th>\n",
       "      <th>accountState - LogOddsForClass_0</th>\n",
       "      <th>paymentInstrumentAgeInAccount</th>\n",
       "      <th>ipState - LogOddsForClass_0</th>\n",
       "      <th>transactionAmount</th>\n",
       "      <th>transactionAmountUSD</th>\n",
       "      <th>ipPostalCode - LogOddsForClass_0</th>\n",
       "      <th>localHour - LogOddsForClass_0</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>720.25</td>\n",
       "      <td>5.064533</td>\n",
       "      <td>0.421214</td>\n",
       "      <td>1.312186</td>\n",
       "      <td>0.566395</td>\n",
       "      <td>3279.574306</td>\n",
       "      <td>1.218157</td>\n",
       "      <td>599.00</td>\n",
       "      <td>626.164650</td>\n",
       "      <td>1.259543</td>\n",
       "      <td>4.745402</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>62</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1185.44</td>\n",
       "      <td>2530.37</td>\n",
       "      <td>0.538996</td>\n",
       "      <td>0.481838</td>\n",
       "      <td>4.401370</td>\n",
       "      <td>4.500157</td>\n",
       "      <td>61.970139</td>\n",
       "      <td>4.035601</td>\n",
       "      <td>1185.44</td>\n",
       "      <td>1185.440000</td>\n",
       "      <td>3.981118</td>\n",
       "      <td>4.921349</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5.064533</td>\n",
       "      <td>5.096396</td>\n",
       "      <td>3.056357</td>\n",
       "      <td>3.155226</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.314186</td>\n",
       "      <td>32.09</td>\n",
       "      <td>32.090000</td>\n",
       "      <td>5.008490</td>\n",
       "      <td>4.742303</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5.064533</td>\n",
       "      <td>5.096396</td>\n",
       "      <td>3.331154</td>\n",
       "      <td>3.331239</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.529398</td>\n",
       "      <td>133.28</td>\n",
       "      <td>132.729554</td>\n",
       "      <td>1.324925</td>\n",
       "      <td>4.745402</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>132.73</td>\n",
       "      <td>5.412885</td>\n",
       "      <td>0.342945</td>\n",
       "      <td>5.563677</td>\n",
       "      <td>4.086965</td>\n",
       "      <td>0.001389</td>\n",
       "      <td>3.529398</td>\n",
       "      <td>543.66</td>\n",
       "      <td>543.660000</td>\n",
       "      <td>2.693451</td>\n",
       "      <td>4.876771</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   accountAge  digitalItemCount  sumPurchaseCount1Day  sumPurchaseAmount1Day  \\\n",
       "0        2000                 0                     0                   0.00   \n",
       "1          62                 1                     1                1185.44   \n",
       "2        2000                 0                     0                   0.00   \n",
       "3           1                 1                     0                   0.00   \n",
       "4           1                 1                     0                   0.00   \n",
       "\n",
       "   sumPurchaseAmount30Day  paymentBillingPostalCode - LogOddsForClass_0  \\\n",
       "0                  720.25                                      5.064533   \n",
       "1                 2530.37                                      0.538996   \n",
       "2                    0.00                                      5.064533   \n",
       "3                    0.00                                      5.064533   \n",
       "4                  132.73                                      5.412885   \n",
       "\n",
       "   accountPostalCode - LogOddsForClass_0  \\\n",
       "0                               0.421214   \n",
       "1                               0.481838   \n",
       "2                               5.096396   \n",
       "3                               5.096396   \n",
       "4                               0.342945   \n",
       "\n",
       "   paymentBillingState - LogOddsForClass_0  accountState - LogOddsForClass_0  \\\n",
       "0                                 1.312186                          0.566395   \n",
       "1                                 4.401370                          4.500157   \n",
       "2                                 3.056357                          3.155226   \n",
       "3                                 3.331154                          3.331239   \n",
       "4                                 5.563677                          4.086965   \n",
       "\n",
       "   paymentInstrumentAgeInAccount  ipState - LogOddsForClass_0  \\\n",
       "0                    3279.574306                     1.218157   \n",
       "1                      61.970139                     4.035601   \n",
       "2                       0.000000                     3.314186   \n",
       "3                       0.000000                     3.529398   \n",
       "4                       0.001389                     3.529398   \n",
       "\n",
       "   transactionAmount  transactionAmountUSD  ipPostalCode - LogOddsForClass_0  \\\n",
       "0             599.00            626.164650                          1.259543   \n",
       "1            1185.44           1185.440000                          3.981118   \n",
       "2              32.09             32.090000                          5.008490   \n",
       "3             133.28            132.729554                          1.324925   \n",
       "4             543.66            543.660000                          2.693451   \n",
       "\n",
       "   localHour - LogOddsForClass_0  Label  \n",
       "0                       4.745402      0  \n",
       "1                       4.921349      0  \n",
       "2                       4.742303      0  \n",
       "3                       4.745402      0  \n",
       "4                       4.876771      0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((138721, 16), 797, 0.0057453449730033666)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape, df.Label.sum(), df.Label.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 15.1\n",
    "\n",
    "Estimate a Logistic Regression and a Decision Tree\n",
    "\n",
    "Evaluate using the following metrics:\n",
    "* Accuracy\n",
    "* F1-Score\n",
    "* F_Beta-Score (Beta=10)\n",
    "\n",
    "Comment about the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************** Regresion Logistica: ******************\n",
      "Accurancy:  0.994112982675349\n",
      "F1 Score:  0.0\n",
      "FBeta Score:  0.0\n",
      "****************** Decision Tree: ******************\n",
      "Accurancy:  0.9888026527620924\n",
      "F1 Score:  0.13382899628252787\n",
      "FBeta Score:  0.12306650871551869\n",
      "****************** Random Forest: ******************\n",
      "Accurancy:  0.9940649253910662\n",
      "F1 Score:  0.09523809523809523\n",
      "FBeta Score:  0.4311986863711002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import fbeta_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "X = df\n",
    "y = df.Label\n",
    "X = X.drop(['Label'], axis=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42)\n",
    "LR = LogisticRegression()\n",
    "DT = DecisionTreeClassifier()\n",
    "RF = RandomForestClassifier()\n",
    "LR.fit(X_train, y_train)\n",
    "DT.fit(X_train, y_train)\n",
    "RF.fit(X_train, y_train)\n",
    "y_predLR = LR.predict(X_test)\n",
    "y_predDT = DT.predict(X_test)\n",
    "y_predRF = RF.predict(X_test)\n",
    "print(\"****************** Regresion Logistica: ******************\")\n",
    "print('Accurancy: ', accuracy_score(y_predLR, y_test))\n",
    "print('F1 Score: ', f1_score(y_predLR, y_test))\n",
    "print('FBeta Score: ', fbeta_score(y_predLR, y_test, beta=10))\n",
    "print(\"****************** Decision Tree: ******************\")\n",
    "print('Accurancy: ', accuracy_score(y_predDT, y_test))\n",
    "print('F1 Score: ', f1_score(y_predDT, y_test))\n",
    "print('FBeta Score: ', fbeta_score(y_predDT, y_test, beta=10))\n",
    "print(\"****************** Random Forest: ******************\")\n",
    "print('Accurancy: ', accuracy_score(y_predRF, y_test))\n",
    "print('F1 Score: ', f1_score(y_predRF, y_test))\n",
    "print('FBeta Score: ', fbeta_score(y_predRF, y_test, beta=10))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 15.2\n",
    "\n",
    "Under-sample the negative class using random-under-sampling\n",
    "\n",
    "Which is parameter for target_percentage did you choose?\n",
    "How the results change?\n",
    "\n",
    "**Only apply under-sampling to the training set, evaluate using the whole test set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def UnderSampling(X, y, target_percentage=0.5, seed=None):\n",
    "    # Assuming minority class is the positive\n",
    "    n_samples = y.shape[0]\n",
    "    n_samples_0 = (y == 0).sum()\n",
    "    n_samples_1 = (y == 1).sum()\n",
    "\n",
    "    n_samples_0_new =  n_samples_1 / target_percentage - n_samples_1\n",
    "    n_samples_0_new_per = n_samples_0_new / n_samples_0\n",
    "\n",
    "    filter_ = y == 0\n",
    "\n",
    "    np.random.seed(seed)\n",
    "    rand_1 = np.random.binomial(n=1, p=n_samples_0_new_per, size=n_samples)\n",
    "    \n",
    "    filter_ = filter_ & rand_1\n",
    "    filter_ = filter_ | (y == 1)\n",
    "    filter_ = filter_.astype(bool)\n",
    "    \n",
    "    return X[filter_], y[filter_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target Percentage:  0.1\n",
      "****************** Regresion Logistica: ******************\n",
      "Accurancy:  0.9914217747555085\n",
      "F1 Score:  0.011080332409972301\n",
      "FBeta Score:  0.017053609117771214\n",
      "****************** Decision Tree: ******************\n",
      "Accurancy:  0.9199125357426052\n",
      "F1 Score:  0.05285592497868712\n",
      "FBeta Score:  0.02866822322940988\n",
      "****************** Random Forest: ******************\n",
      "Accurancy:  0.9827714635845929\n",
      "F1 Score:  0.15348288075560804\n",
      "FBeta Score:  0.1086111340888411\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target Percentage:  0.2\n",
      "****************** Regresion Logistica: ******************\n",
      "Accurancy:  0.9779417065141649\n",
      "F1 Score:  0.04375\n",
      "FBeta Score:  0.029563035751620323\n",
      "****************** Decision Tree: ******************\n",
      "Accurancy:  0.8617151644760555\n",
      "F1 Score:  0.04226992844067232\n",
      "FBeta Score:  0.022244188365458814\n",
      "****************** Random Forest: ******************\n",
      "Accurancy:  0.9594396520652618\n",
      "F1 Score:  0.09635974304068523\n",
      "FBeta Score:  0.05592297517610508\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target Percentage:  0.3\n",
      "****************** Regresion Logistica: ******************\n",
      "Accurancy:  0.950116538914386\n",
      "F1 Score:  0.04155124653739612\n",
      "FBeta Score:  0.0236294158933167\n",
      "****************** Decision Tree: ******************\n",
      "Accurancy:  0.7869620587740587\n",
      "F1 Score:  0.0327296530656775\n",
      "FBeta Score:  0.016977738430763886\n",
      "****************** Random Forest: ******************\n",
      "Accurancy:  0.901410481293702\n",
      "F1 Score:  0.06131320064058568\n",
      "FBeta Score:  0.032782279063571076\n",
      "Target Percentage: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0.4\n",
      "****************** Regresion Logistica: ******************\n",
      "Accurancy:  0.8815628228848787\n",
      "F1 Score:  0.03674027750635138\n",
      "FBeta Score:  0.01947706920780806\n",
      "****************** Decision Tree: ******************\n",
      "Accurancy:  0.721435951654372\n",
      "F1 Score:  0.024568784181741694\n",
      "FBeta Score:  0.01266571898526513\n",
      "****************** Random Forest: ******************\n",
      "Accurancy:  0.8455919455991542\n",
      "F1 Score:  0.04118173679498657\n",
      "FBeta Score:  0.021577688502891115\n",
      "Target Percentage:  0.5\n",
      "****************** Regresion Logistica: ******************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accurancy:  0.5441766585770238\n",
      "F1 Score:  0.01933416046319272\n",
      "FBeta Score:  0.00988773103612553\n",
      "****************** Decision Tree: ******************\n",
      "Accurancy:  0.6491337674508013\n",
      "F1 Score:  0.021838156484458734\n",
      "FBeta Score:  0.011210415751645336\n",
      "****************** Random Forest: ******************\n",
      "Accurancy:  0.7703582670543287\n",
      "F1 Score:  0.032594392144953944\n",
      "FBeta Score:  0.016874471408039264\n",
      "Target Percentage:  0.6\n",
      "****************** Regresion Logistica: ******************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accurancy:  0.3980344570728308\n",
      "F1 Score:  0.017414496391590838\n",
      "FBeta Score:  0.00887878685882523\n",
      "****************** Decision Tree: ******************\n",
      "Accurancy:  0.6155417257370785\n",
      "F1 Score:  0.02152641878669276\n",
      "FBeta Score:  0.011034517007098317\n",
      "****************** Random Forest: ******************\n",
      "Accurancy:  0.6739553547829013\n",
      "F1 Score:  0.026544228423846763\n",
      "FBeta Score:  0.013642221159497534\n",
      "Target Percentage:  0.7\n",
      "****************** Regresion Logistica: ******************\n",
      "Accurancy:  0.27440709325516016\n",
      "F1 Score:  0.015261699005380729\n",
      "FBeta Score:  0.007768605092620746\n",
      "****************** Decision Tree: ******************\n",
      "Accurancy:  0.5048898286757816\n",
      "F1 Score:  0.018014583234046606\n",
      "FBeta Score:  0.009203754016908986\n",
      "****************** Random Forest: ******************\n",
      "Accurancy:  0.5577047841026503\n",
      "F1 Score:  0.021372747089159448\n",
      "FBeta Score:  0.010934238909430722\n",
      "Target Percentage: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0.8\n",
      "****************** Regresion Logistica: ******************\n",
      "Accurancy:  0.12833697767739144\n",
      "F1 Score:  0.013112791773219435\n",
      "FBeta Score:  0.006665945510735867\n",
      "****************** Decision Tree: ******************\n",
      "Accurancy:  0.3916668669053512\n",
      "F1 Score:  0.015247578668948618\n",
      "FBeta Score:  0.007773364563965533\n",
      "****************** Random Forest: ******************\n",
      "Accurancy:  0.3517072350241488\n",
      "F1 Score:  0.016261941223656384\n",
      "FBeta Score:  0.00828555610123071\n",
      "Target Percentage:  0.9\n",
      "****************** Regresion Logistica: ******************\n",
      "Accurancy:  0.02486964461638273\n",
      "F1 Score:  0.011930268796260227\n",
      "FBeta Score:  0.006060576373181613\n",
      "****************** Decision Tree: ******************\n",
      "Accurancy:  0.23399091717327053\n",
      "F1 Score:  0.01410236585743003\n",
      "FBeta Score:  0.007175519475764549\n",
      "****************** Random Forest: ******************\n",
      "Accurancy:  0.11987889564360718\n",
      "F1 Score:  0.012828805519620524\n",
      "FBeta Score:  0.006521175916845376\n"
     ]
    }
   ],
   "source": [
    "resultados =[]\n",
    "for target_percentage in [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42)\n",
    "    X_train, y_train = UnderSampling(X_train, y_train, target_percentage, 1)\n",
    "    LR.fit(X_train, y_train)\n",
    "    DT.fit(X_train, y_train)\n",
    "    RF.fit(X_train, y_train)\n",
    "    y_predLR = LR.predict(X_test)\n",
    "    y_predDT = DT.predict(X_test)\n",
    "    y_predRF = RF.predict(X_test)\n",
    "    print('Target Percentage: ', target_percentage)\n",
    "    print(\"****************** Regresion Logistica: ******************\")\n",
    "    print('Accurancy: ', accuracy_score(y_predLR, y_test))\n",
    "    print('F1 Score: ', f1_score(y_predLR, y_test))\n",
    "    print('FBeta Score: ', fbeta_score(y_predLR, y_test, beta=10))\n",
    "    resultados.append([\"RL\", \"Under-Sampling\", accuracy_score(y_predLR, y_test),  f1_score(y_predLR, y_test), fbeta_score(y_predLR, y_test, beta=10)])\n",
    "    print(\"****************** Decision Tree: ******************\")\n",
    "    print('Accurancy: ', accuracy_score(y_predDT, y_test))\n",
    "    print('F1 Score: ', f1_score(y_predDT, y_test))\n",
    "    print('FBeta Score: ', fbeta_score(y_predDT, y_test, beta=10))\n",
    "    resultados.append([\"DT\", \"Under-Sampling\",  accuracy_score(y_predDT, y_test),  f1_score(y_predDT, y_test), fbeta_score(y_predDT, y_test, beta=10)])\n",
    "    print(\"****************** Random Forest: ******************\")\n",
    "    print('Accurancy: ', accuracy_score(y_predRF, y_test))\n",
    "    print('F1 Score: ', f1_score(y_predRF, y_test))\n",
    "    print('FBeta Score: ', fbeta_score(y_predRF, y_test, beta=10))\n",
    "    resultados.append([\"RF\",  \"Under-Sampling\", accuracy_score(y_predRF, y_test),  f1_score(y_predRF, y_test), fbeta_score(y_predRF, y_test, beta=10)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 15.3\n",
    "\n",
    "Same analysis using random-over-sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def OverSampling(X, y, target_percentage=0.5, seed=None):\n",
    "    # Assuming minority class is the positive\n",
    "    n_samples = y.shape[0]\n",
    "    n_samples_0 = (y == 0).sum()\n",
    "    n_samples_1 = (y == 1).sum()\n",
    "\n",
    "    n_samples_1_new =  -target_percentage * n_samples_0 / (target_percentage- 1)\n",
    "\n",
    "    np.random.seed(seed)\n",
    "    filter_ = np.random.choice(X[y == 1].shape[0], int(n_samples_1_new))\n",
    "    # filter_ is within the positives, change to be of all\n",
    "    filter_ = np.nonzero(y == 1)[0][filter_]\n",
    "    \n",
    "    filter_ = np.concatenate((filter_, np.nonzero(y == 0)[0]), axis=0)\n",
    "    \n",
    "    return X[filter_], y[filter_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target Percentage:  0.1\n",
      "****************** Regresion Logistica: ******************\n",
      "Accurancy:  0.9012941816204459\n",
      "F1 Score:  0.0\n",
      "FBeta Score:  0.0\n",
      "****************** Decision Tree: ******************\n",
      "Accurancy:  0.9928874388254486\n",
      "F1 Score:  0.9651423089222898\n",
      "FBeta Score:  0.9343882386840864\n",
      "****************** Random Forest: ******************\n",
      "Accurancy:  0.998194671016857\n",
      "F1 Score:  0.9909160555981176\n",
      "FBeta Score:  0.9834255688454036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target Percentage:  0.2\n",
      "****************** Regresion Logistica: ******************\n",
      "Accurancy:  0.8058273075287112\n",
      "F1 Score:  0.12219211607376976\n",
      "FBeta Score:  0.5661643824630905\n",
      "****************** Decision Tree: ******************\n",
      "Accurancy:  0.9945091063763969\n",
      "F1 Score:  0.9863971644793562\n",
      "FBeta Score:  0.9734181207921774\n",
      "****************** Random Forest: ******************\n",
      "Accurancy:  0.9985499400641893\n",
      "F1 Score:  0.9963713774251294\n",
      "FBeta Score:  0.9928400749596419\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target Percentage:  0.3\n",
      "****************** Regresion Logistica: ******************\n",
      "Accurancy:  0.7362250680922332\n",
      "F1 Score:  0.33645416631202657\n",
      "FBeta Score:  0.6576363483626337\n",
      "****************** Decision Tree: ******************\n",
      "Accurancy:  0.9950601410904908\n",
      "F1 Score:  0.9917741844610963\n",
      "FBeta Score:  0.9838415408529563\n",
      "****************** Random Forest: ******************\n",
      "Accurancy:  0.9987819525976552\n",
      "F1 Score:  0.997959067974375\n",
      "FBeta Score:  0.9959666192931165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target Percentage:  0.4\n",
      "****************** Regresion Logistica: ******************\n",
      "Accurancy:  0.6835648618079522\n",
      "F1 Score:  0.4659585923351769\n",
      "FBeta Score:  0.6975866832275064\n",
      "****************** Decision Tree: ******************\n",
      "Accurancy:  0.9960412981062035\n",
      "F1 Score:  0.9950342870655001\n",
      "FBeta Score:  0.9902145346778253\n",
      "****************** Random Forest: ******************\n",
      "Accurancy:  0.9990429511905107\n",
      "F1 Score:  0.9987949607449332\n",
      "FBeta Score:  0.9976165988721457\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target Percentage:  0.5\n",
      "****************** Regresion Logistica: ******************\n",
      "Accurancy:  0.6543290435623225\n",
      "F1 Score:  0.6866126205083259\n",
      "FBeta Score:  0.6257473540488545\n",
      "****************** Decision Tree: ******************\n",
      "Accurancy:  0.996531931605341\n",
      "F1 Score:  0.9965215915839484\n",
      "FBeta Score:  0.9931354673658443\n",
      "****************** Random Forest: ******************\n",
      "Accurancy:  0.9993112198658691\n",
      "F1 Score:  0.9993072351389783\n",
      "FBeta Score:  0.998629119286103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target Percentage:  0.6\n",
      "****************** Regresion Logistica: ******************\n",
      "Accurancy:  0.685623966822308\n",
      "F1 Score:  0.7721604125213687\n",
      "FBeta Score:  0.6842926620796391\n",
      "****************** Decision Tree: ******************\n",
      "Accurancy:  0.9974285355219783\n",
      "F1 Score:  0.9978600160901046\n",
      "FBeta Score:  0.9957712782996468\n",
      "****************** Random Forest: ******************\n",
      "Accurancy:  0.9993909689394159\n",
      "F1 Score:  0.9994923326107803\n",
      "FBeta Score:  0.998995218035294\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target Percentage:  0.7\n",
      "****************** Regresion Logistica: ******************\n",
      "Accurancy:  0.7358400278414199\n",
      "F1 Score:  0.8340348383805254\n",
      "FBeta Score:  0.7452371102046962\n",
      "****************** Decision Tree: ******************\n",
      "Accurancy:  0.9980133986833328\n",
      "F1 Score:  0.998581163652934\n",
      "FBeta Score:  0.9971943250411303\n",
      "****************** Random Forest: ******************\n",
      "Accurancy:  0.9996012296627128\n",
      "F1 Score:  0.9997148737409084\n",
      "FBeta Score:  0.9994355512985861\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target Percentage:  0.8\n",
      "****************** Regresion Logistica: ******************\n",
      "Accurancy:  0.8018328934775674\n",
      "F1 Score:  0.8861836918259247\n",
      "FBeta Score:  0.8204104773379918\n",
      "****************** Decision Tree: ******************\n",
      "Accurancy:  0.99877227071914\n",
      "F1 Score:  0.9992326376720523\n",
      "FBeta Score:  0.9984816127185857\n",
      "****************** Random Forest: ******************\n",
      "Accurancy:  0.9995988128727898\n",
      "F1 Score:  0.9997491181351316\n",
      "FBeta Score:  0.9995033263669371\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target Percentage:  0.9\n",
      "****************** Regresion Logistica: ******************\n",
      "Accurancy:  0.9011605425210019\n",
      "F1 Score:  0.9479052953247623\n",
      "FBeta Score:  0.9028555534979446\n",
      "****************** Decision Tree: ******************\n",
      "Accurancy:  0.9994078864688766\n",
      "F1 Score:  0.9996712878673023\n",
      "FBeta Score:  0.9993492945449848\n",
      "****************** Random Forest: ******************\n",
      "Accurancy:  0.9998356582852392\n",
      "F1 Score:  0.999908743940866\n",
      "FBeta Score:  0.9998193110948516\n"
     ]
    }
   ],
   "source": [
    "for target_percentage in [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]:\n",
    "    X_t, y_t = OverSampling(X.values, y, target_percentage, 1)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_t, y_t, test_size=0.30, random_state=42)\n",
    "    LR.fit(X_train, y_train)\n",
    "    DT.fit(X_train, y_train)\n",
    "    RF.fit(X_train, y_train)\n",
    "    y_predLR = LR.predict(X_test)\n",
    "    y_predDT = DT.predict(X_test)\n",
    "    y_predRF = RF.predict(X_test)\n",
    "    print('Target Percentage: ', target_percentage)\n",
    "    print(\"****************** Regresion Logistica: ******************\")\n",
    "    print('Accurancy: ', accuracy_score(y_predLR, y_test))\n",
    "    print('F1 Score: ', f1_score(y_predLR, y_test))\n",
    "    print('FBeta Score: ', fbeta_score(y_predLR, y_test, beta=10))\n",
    "    resultados.append([\"RL\", \"Over-Sampling\", accuracy_score(y_predLR, y_test),  f1_score(y_predLR, y_test), fbeta_score(y_predLR, y_test, beta=10)])\n",
    "    print(\"****************** Decision Tree: ******************\")\n",
    "    print('Accurancy: ', accuracy_score(y_predDT, y_test))\n",
    "    print('F1 Score: ', f1_score(y_predDT, y_test))\n",
    "    print('FBeta Score: ', fbeta_score(y_predDT, y_test, beta=10))\n",
    "    resultados.append([\"DT\", \"Over-Sampling\",  accuracy_score(y_predDT, y_test),  f1_score(y_predDT, y_test), fbeta_score(y_predDT, y_test, beta=10)])\n",
    "    print(\"****************** Random Forest: ******************\")\n",
    "    print('Accurancy: ', accuracy_score(y_predRF, y_test))\n",
    "    print('F1 Score: ', f1_score(y_predRF, y_test))\n",
    "    print('FBeta Score: ', fbeta_score(y_predRF, y_test, beta=10))\n",
    "    resultados.append([\"RF\",  \"Over-Sampling\", accuracy_score(y_predRF, y_test),  f1_score(y_predRF, y_test), fbeta_score(y_predRF, y_test, beta=10)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 15.4 (3 points)\n",
    "\n",
    "Evaluate the results using SMOTE\n",
    "\n",
    "Which parameters did you choose?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SMOTE(X, y, target_percentage=0.5, k=5, seed=None):\n",
    "    # Calculate the NearestNeighbors\n",
    "    from sklearn.neighbors import NearestNeighbors\n",
    "    nearest_neighbour_ = NearestNeighbors(n_neighbors=k + 1)\n",
    "    nearest_neighbour_.fit(X[y==1])\n",
    "    nns = nearest_neighbour_.kneighbors(X[y==1], \n",
    "                                    return_distance=False)[:, 1:]\n",
    "    \n",
    "    # New samples\n",
    "    n_samples_1_new =  int(-target_percentage * n_samples_0 / (target_percentage- 1) - n_samples_1)\n",
    "    \n",
    "    # A matrix to store the synthetic samples\n",
    "    new = np.zeros((n_samples_1_new, X.shape[1]))\n",
    "    \n",
    "    # Create seeds\n",
    "    np.random.seed(seed)\n",
    "    seeds = np.random.randint(1, 1000000, 3)\n",
    "    \n",
    "    # Select examples to use as base\n",
    "    np.random.seed(seeds[0])\n",
    "    sel_ = np.random.choice(y[y==1].shape[0], n_samples_1_new)\n",
    "    \n",
    "    # Define random seeds (2 per example)\n",
    "    np.random.seed(seeds[1])\n",
    "    nn__=[]\n",
    "    # Select one random neighbor for each example to use as base\n",
    "    for i, sel in enumerate(sel_):\n",
    "        nn__.append(np.random.choice(nns[sel]))\n",
    "    \n",
    "    np.random.seed(seeds[2])\n",
    "    steps = np.random.uniform(size=n_samples_1_new)  \n",
    "\n",
    "    # For each selected examples create one synthetic case\n",
    "    for i, sel in enumerate(sel_):\n",
    "        # Select neighbor\n",
    "        nn_ = nn__[i]\n",
    "        step = steps[i]\n",
    "        # Create new sample\n",
    "        new[i, :] = X[y==1][sel] - step * (X[y==1][sel] - X[y==1][nn_])\n",
    "    \n",
    "    X = np.vstack((X, new))\n",
    "    y = np.append(y, np.ones(n_samples_1_new))\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target Percentage:  0.1\n",
      "****************** Regresion Logistica: ******************\n",
      "Accurancy:  0.9914217747555085\n",
      "F1 Score:  0.011080332409972301\n",
      "FBeta Score:  0.017053609117771214\n",
      "****************** Decision Tree: ******************\n",
      "Accurancy:  0.9199125357426052\n",
      "F1 Score:  0.05285592497868712\n",
      "FBeta Score:  0.02866822322940988\n",
      "****************** Random Forest: ******************\n",
      "Accurancy:  0.9827714635845929\n",
      "F1 Score:  0.15348288075560804\n",
      "FBeta Score:  0.1086111340888411\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target Percentage:  0.2\n",
      "****************** Regresion Logistica: ******************\n",
      "Accurancy:  0.9779417065141649\n",
      "F1 Score:  0.04375\n",
      "FBeta Score:  0.029563035751620323\n",
      "****************** Decision Tree: ******************\n",
      "Accurancy:  0.8617151644760555\n",
      "F1 Score:  0.04226992844067232\n",
      "FBeta Score:  0.022244188365458814\n",
      "****************** Random Forest: ******************\n",
      "Accurancy:  0.9594396520652618\n",
      "F1 Score:  0.09635974304068523\n",
      "FBeta Score:  0.05592297517610508\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target Percentage:  0.3\n",
      "****************** Regresion Logistica: ******************\n",
      "Accurancy:  0.950116538914386\n",
      "F1 Score:  0.04155124653739612\n",
      "FBeta Score:  0.0236294158933167\n",
      "****************** Decision Tree: ******************\n",
      "Accurancy:  0.7869620587740587\n",
      "F1 Score:  0.0327296530656775\n",
      "FBeta Score:  0.016977738430763886\n",
      "****************** Random Forest: ******************\n",
      "Accurancy:  0.901410481293702\n",
      "F1 Score:  0.06131320064058568\n",
      "FBeta Score:  0.032782279063571076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target Percentage:  0.4\n",
      "****************** Regresion Logistica: ******************\n",
      "Accurancy:  0.8815628228848787\n",
      "F1 Score:  0.03674027750635138\n",
      "FBeta Score:  0.01947706920780806\n",
      "****************** Decision Tree: ******************\n",
      "Accurancy:  0.721435951654372\n",
      "F1 Score:  0.024568784181741694\n",
      "FBeta Score:  0.01266571898526513\n",
      "****************** Random Forest: ******************\n",
      "Accurancy:  0.8455919455991542\n",
      "F1 Score:  0.04118173679498657\n",
      "FBeta Score:  0.021577688502891115\n",
      "Target Percentage:  0.5\n",
      "****************** Regresion Logistica: ******************\n",
      "Accurancy:  0.5441766585770238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score:  0.01933416046319272\n",
      "FBeta Score:  0.00988773103612553\n",
      "****************** Decision Tree: ******************\n",
      "Accurancy:  0.6491337674508013\n",
      "F1 Score:  0.021838156484458734\n",
      "FBeta Score:  0.011210415751645336\n",
      "****************** Random Forest: ******************\n",
      "Accurancy:  0.7703582670543287\n",
      "F1 Score:  0.032594392144953944\n",
      "FBeta Score:  0.016874471408039264\n",
      "Target Percentage:  0.6\n",
      "****************** Regresion Logistica: ******************\n",
      "Accurancy:  0.3980344570728308\n",
      "F1 Score:  0.017414496391590838\n",
      "FBeta Score: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0.00887878685882523\n",
      "****************** Decision Tree: ******************\n",
      "Accurancy:  0.6155417257370785\n",
      "F1 Score:  0.02152641878669276\n",
      "FBeta Score:  0.011034517007098317\n",
      "****************** Random Forest: ******************\n",
      "Accurancy:  0.6739553547829013\n",
      "F1 Score:  0.026544228423846763\n",
      "FBeta Score:  0.013642221159497534\n",
      "Target Percentage:  0.7\n",
      "****************** Regresion Logistica: ******************\n",
      "Accurancy:  0.27440709325516016\n",
      "F1 Score:  0.015261699005380729\n",
      "FBeta Score:  0.007768605092620746\n",
      "****************** Decision Tree: ******************"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accurancy:  0.5048898286757816\n",
      "F1 Score:  0.018014583234046606\n",
      "FBeta Score:  0.009203754016908986\n",
      "****************** Random Forest: ******************\n",
      "Accurancy:  0.5577047841026503\n",
      "F1 Score:  0.021372747089159448\n",
      "FBeta Score:  0.010934238909430722\n",
      "Target Percentage:  0.8\n",
      "****************** Regresion Logistica: ******************\n",
      "Accurancy:  0.12833697767739144\n",
      "F1 Score:  0.013112791773219435\n",
      "FBeta Score:  0.006665945510735867\n",
      "****************** Decision Tree: ******************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accurancy:  0.3916668669053512\n",
      "F1 Score:  0.015247578668948618\n",
      "FBeta Score:  0.007773364563965533\n",
      "****************** Random Forest: ******************\n",
      "Accurancy:  0.3517072350241488\n",
      "F1 Score:  0.016261941223656384\n",
      "FBeta Score:  0.00828555610123071\n",
      "Target Percentage:  0.9\n",
      "****************** Regresion Logistica: ******************\n",
      "Accurancy:  0.02486964461638273\n",
      "F1 Score:  0.011930268796260227\n",
      "FBeta Score:  0.006060576373181613\n",
      "****************** Decision Tree: ******************\n",
      "Accurancy:  0.23399091717327053\n",
      "F1 Score:  0.01410236585743003\n",
      "FBeta Score:  0.007175519475764549\n",
      "****************** Random Forest: ******************\n",
      "Accurancy:  0.11987889564360718\n",
      "F1 Score:  0.012828805519620524\n",
      "FBeta Score:  0.006521175916845376\n"
     ]
    }
   ],
   "source": [
    "for target_percentage in [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42)\n",
    "    X_train, y_train = UnderSampling(X_train, y_train, target_percentage, 1)\n",
    "    LR.fit(X_train, y_train)\n",
    "    DT.fit(X_train, y_train)\n",
    "    RF.fit(X_train, y_train)\n",
    "    y_predLR = LR.predict(X_test)\n",
    "    y_predDT = DT.predict(X_test)\n",
    "    y_predRF = RF.predict(X_test)\n",
    "    print('Target Percentage: ', target_percentage)\n",
    "    print(\"****************** Regresion Logistica: ******************\")\n",
    "    print('Accurancy: ', accuracy_score(y_predLR, y_test))\n",
    "    print('F1 Score: ', f1_score(y_predLR, y_test))\n",
    "    print('FBeta Score: ', fbeta_score(y_predLR, y_test, beta=10))\n",
    "    resultados.append([\"RL\", \"SMOTE-Sampling\", accuracy_score(y_predLR, y_test),  f1_score(y_predLR, y_test), fbeta_score(y_predLR, y_test, beta=10)])\n",
    "    print(\"****************** Decision Tree: ******************\")\n",
    "    print('Accurancy: ', accuracy_score(y_predDT, y_test))\n",
    "    print('F1 Score: ', f1_score(y_predDT, y_test))\n",
    "    print('FBeta Score: ', fbeta_score(y_predDT, y_test, beta=10))\n",
    "    resultados.append([\"DT\", \"SMOTE-Sampling\",  accuracy_score(y_predDT, y_test),  f1_score(y_predDT, y_test), fbeta_score(y_predDT, y_test, beta=10)])\n",
    "    print(\"****************** Random Forest: ******************\")\n",
    "    print('Accurancy: ', accuracy_score(y_predRF, y_test))\n",
    "    print('F1 Score: ', f1_score(y_predRF, y_test))\n",
    "    print('FBeta Score: ', fbeta_score(y_predRF, y_test, beta=10))\n",
    "    resultados.append([\"RF\",  \"SMOTE-Sampling\", accuracy_score(y_predRF, y_test),  f1_score(y_predRF, y_test), fbeta_score(y_predRF, y_test, beta=10)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 15.5 (3 points)\n",
    "\n",
    "Evaluate the results using Adaptive Synthetic Sampling Approach for Imbalanced\n",
    "Learning (ADASYN)\n",
    "\n",
    "http://www.ele.uri.edu/faculty/he/PDFfiles/adasyn.pdf\n",
    "https://imbalanced-learn.readthedocs.io/en/stable/generated/imblearn.over_sampling.ADASYN.html#rf9172e970ca5-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************** Regresion Logistica: ******************\n",
      "Accurancy:  0.5725064276617728\n",
      "F1 Score:  0.01907702486629542\n",
      "FBeta Score:  0.009764480048283125\n",
      "****************** Decision Tree: ******************\n",
      "Accurancy:  0.9835163514909773\n",
      "F1 Score:  0.08288770053475936\n",
      "FBeta Score:  0.06194480166188545\n",
      "****************** Random Forest: ******************\n",
      "Accurancy:  0.9925270922940145\n",
      "F1 Score:  0.15258855585831063\n",
      "FBeta Score:  0.2272398553635998\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "from imblearn.over_sampling import ADASYN \n",
    "ada = ADASYN(random_state=42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42)\n",
    "X_train, y_train = ada.fit_resample(X_train, y_train)\n",
    "LR.fit(X_train, y_train)\n",
    "DT.fit(X_train, y_train)\n",
    "RF.fit(X_train, y_train)\n",
    "y_predLR = LR.predict(X_test)\n",
    "y_predDT = DT.predict(X_test)\n",
    "y_predRF = RF.predict(X_test)\n",
    "print(\"****************** Regresion Logistica: ******************\")\n",
    "print('Accurancy: ', accuracy_score(y_predLR, y_test))\n",
    "print('F1 Score: ', f1_score(y_predLR, y_test))\n",
    "print('FBeta Score: ', fbeta_score(y_predLR, y_test, beta=10))\n",
    "resultados.append([\"RL\", \"ADASYN-Sampling\", accuracy_score(y_predLR, y_test),  f1_score(y_predLR, y_test), fbeta_score(y_predLR, y_test, beta=10)])\n",
    "print(\"****************** Decision Tree: ******************\")\n",
    "print('Accurancy: ', accuracy_score(y_predDT, y_test))\n",
    "print('F1 Score: ', f1_score(y_predDT, y_test))\n",
    "print('FBeta Score: ', fbeta_score(y_predDT, y_test, beta=10))\n",
    "resultados.append([\"DT\", \"ADASYN-Sampling\",  accuracy_score(y_predDT, y_test),  f1_score(y_predDT, y_test), fbeta_score(y_predDT, y_test, beta=10)])\n",
    "print(\"****************** Random Forest: ******************\")\n",
    "print('Accurancy: ', accuracy_score(y_predRF, y_test))\n",
    "print('F1 Score: ', f1_score(y_predRF, y_test))\n",
    "print('FBeta Score: ', fbeta_score(y_predRF, y_test, beta=10))\n",
    "resultados.append([\"RF\",  \"ADASYN-Sampling\", accuracy_score(y_predRF, y_test),  f1_score(y_predRF, y_test), fbeta_score(y_predRF, y_test, beta=10)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 15.6 (3 points)\n",
    "\n",
    "Compare and comment about the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultados = pd.DataFrame(resultados, columns=[\"Model\", \"Method\", \"Acc\", \"F1 Score\", \"FBeta Score-b10\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Method</th>\n",
       "      <th>Acc</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>FBeta Score-b10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RL</td>\n",
       "      <td>Under-Sampling</td>\n",
       "      <td>0.991422</td>\n",
       "      <td>0.011080</td>\n",
       "      <td>0.017054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DT</td>\n",
       "      <td>Under-Sampling</td>\n",
       "      <td>0.919913</td>\n",
       "      <td>0.052856</td>\n",
       "      <td>0.028668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RF</td>\n",
       "      <td>Under-Sampling</td>\n",
       "      <td>0.982771</td>\n",
       "      <td>0.153483</td>\n",
       "      <td>0.108611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RL</td>\n",
       "      <td>Under-Sampling</td>\n",
       "      <td>0.977942</td>\n",
       "      <td>0.043750</td>\n",
       "      <td>0.029563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DT</td>\n",
       "      <td>Under-Sampling</td>\n",
       "      <td>0.861715</td>\n",
       "      <td>0.042270</td>\n",
       "      <td>0.022244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RF</td>\n",
       "      <td>Under-Sampling</td>\n",
       "      <td>0.959440</td>\n",
       "      <td>0.096360</td>\n",
       "      <td>0.055923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>RL</td>\n",
       "      <td>Under-Sampling</td>\n",
       "      <td>0.950117</td>\n",
       "      <td>0.041551</td>\n",
       "      <td>0.023629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>DT</td>\n",
       "      <td>Under-Sampling</td>\n",
       "      <td>0.786962</td>\n",
       "      <td>0.032730</td>\n",
       "      <td>0.016978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>RF</td>\n",
       "      <td>Under-Sampling</td>\n",
       "      <td>0.901410</td>\n",
       "      <td>0.061313</td>\n",
       "      <td>0.032782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>RL</td>\n",
       "      <td>Under-Sampling</td>\n",
       "      <td>0.881563</td>\n",
       "      <td>0.036740</td>\n",
       "      <td>0.019477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>DT</td>\n",
       "      <td>Under-Sampling</td>\n",
       "      <td>0.721436</td>\n",
       "      <td>0.024569</td>\n",
       "      <td>0.012666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>RF</td>\n",
       "      <td>Under-Sampling</td>\n",
       "      <td>0.845592</td>\n",
       "      <td>0.041182</td>\n",
       "      <td>0.021578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>RL</td>\n",
       "      <td>Under-Sampling</td>\n",
       "      <td>0.544177</td>\n",
       "      <td>0.019334</td>\n",
       "      <td>0.009888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>DT</td>\n",
       "      <td>Under-Sampling</td>\n",
       "      <td>0.649134</td>\n",
       "      <td>0.021838</td>\n",
       "      <td>0.011210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>RF</td>\n",
       "      <td>Under-Sampling</td>\n",
       "      <td>0.770358</td>\n",
       "      <td>0.032594</td>\n",
       "      <td>0.016874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>RL</td>\n",
       "      <td>Under-Sampling</td>\n",
       "      <td>0.398034</td>\n",
       "      <td>0.017414</td>\n",
       "      <td>0.008879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>DT</td>\n",
       "      <td>Under-Sampling</td>\n",
       "      <td>0.615542</td>\n",
       "      <td>0.021526</td>\n",
       "      <td>0.011035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>RF</td>\n",
       "      <td>Under-Sampling</td>\n",
       "      <td>0.673955</td>\n",
       "      <td>0.026544</td>\n",
       "      <td>0.013642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>RL</td>\n",
       "      <td>Under-Sampling</td>\n",
       "      <td>0.274407</td>\n",
       "      <td>0.015262</td>\n",
       "      <td>0.007769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>DT</td>\n",
       "      <td>Under-Sampling</td>\n",
       "      <td>0.504890</td>\n",
       "      <td>0.018015</td>\n",
       "      <td>0.009204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>RF</td>\n",
       "      <td>Under-Sampling</td>\n",
       "      <td>0.557705</td>\n",
       "      <td>0.021373</td>\n",
       "      <td>0.010934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>RL</td>\n",
       "      <td>Under-Sampling</td>\n",
       "      <td>0.128337</td>\n",
       "      <td>0.013113</td>\n",
       "      <td>0.006666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>DT</td>\n",
       "      <td>Under-Sampling</td>\n",
       "      <td>0.391667</td>\n",
       "      <td>0.015248</td>\n",
       "      <td>0.007773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>RF</td>\n",
       "      <td>Under-Sampling</td>\n",
       "      <td>0.351707</td>\n",
       "      <td>0.016262</td>\n",
       "      <td>0.008286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>RL</td>\n",
       "      <td>Under-Sampling</td>\n",
       "      <td>0.024870</td>\n",
       "      <td>0.011930</td>\n",
       "      <td>0.006061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>DT</td>\n",
       "      <td>Under-Sampling</td>\n",
       "      <td>0.233991</td>\n",
       "      <td>0.014102</td>\n",
       "      <td>0.007176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>RF</td>\n",
       "      <td>Under-Sampling</td>\n",
       "      <td>0.119879</td>\n",
       "      <td>0.012829</td>\n",
       "      <td>0.006521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>RL</td>\n",
       "      <td>Over-Sampling</td>\n",
       "      <td>0.901294</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>DT</td>\n",
       "      <td>Over-Sampling</td>\n",
       "      <td>0.992887</td>\n",
       "      <td>0.965142</td>\n",
       "      <td>0.934388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>RF</td>\n",
       "      <td>Over-Sampling</td>\n",
       "      <td>0.998195</td>\n",
       "      <td>0.990916</td>\n",
       "      <td>0.983426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>RL</td>\n",
       "      <td>SMOTE-Sampling</td>\n",
       "      <td>0.991422</td>\n",
       "      <td>0.011080</td>\n",
       "      <td>0.017054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>DT</td>\n",
       "      <td>SMOTE-Sampling</td>\n",
       "      <td>0.919913</td>\n",
       "      <td>0.052856</td>\n",
       "      <td>0.028668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>RF</td>\n",
       "      <td>SMOTE-Sampling</td>\n",
       "      <td>0.982771</td>\n",
       "      <td>0.153483</td>\n",
       "      <td>0.108611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>RL</td>\n",
       "      <td>SMOTE-Sampling</td>\n",
       "      <td>0.977942</td>\n",
       "      <td>0.043750</td>\n",
       "      <td>0.029563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>DT</td>\n",
       "      <td>SMOTE-Sampling</td>\n",
       "      <td>0.861715</td>\n",
       "      <td>0.042270</td>\n",
       "      <td>0.022244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>RF</td>\n",
       "      <td>SMOTE-Sampling</td>\n",
       "      <td>0.959440</td>\n",
       "      <td>0.096360</td>\n",
       "      <td>0.055923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>RL</td>\n",
       "      <td>SMOTE-Sampling</td>\n",
       "      <td>0.950117</td>\n",
       "      <td>0.041551</td>\n",
       "      <td>0.023629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>DT</td>\n",
       "      <td>SMOTE-Sampling</td>\n",
       "      <td>0.786962</td>\n",
       "      <td>0.032730</td>\n",
       "      <td>0.016978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>RF</td>\n",
       "      <td>SMOTE-Sampling</td>\n",
       "      <td>0.901410</td>\n",
       "      <td>0.061313</td>\n",
       "      <td>0.032782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>RL</td>\n",
       "      <td>SMOTE-Sampling</td>\n",
       "      <td>0.881563</td>\n",
       "      <td>0.036740</td>\n",
       "      <td>0.019477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>DT</td>\n",
       "      <td>SMOTE-Sampling</td>\n",
       "      <td>0.721436</td>\n",
       "      <td>0.024569</td>\n",
       "      <td>0.012666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>RF</td>\n",
       "      <td>SMOTE-Sampling</td>\n",
       "      <td>0.845592</td>\n",
       "      <td>0.041182</td>\n",
       "      <td>0.021578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>RL</td>\n",
       "      <td>SMOTE-Sampling</td>\n",
       "      <td>0.544177</td>\n",
       "      <td>0.019334</td>\n",
       "      <td>0.009888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>DT</td>\n",
       "      <td>SMOTE-Sampling</td>\n",
       "      <td>0.649134</td>\n",
       "      <td>0.021838</td>\n",
       "      <td>0.011210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>RF</td>\n",
       "      <td>SMOTE-Sampling</td>\n",
       "      <td>0.770358</td>\n",
       "      <td>0.032594</td>\n",
       "      <td>0.016874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>RL</td>\n",
       "      <td>SMOTE-Sampling</td>\n",
       "      <td>0.398034</td>\n",
       "      <td>0.017414</td>\n",
       "      <td>0.008879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>DT</td>\n",
       "      <td>SMOTE-Sampling</td>\n",
       "      <td>0.615542</td>\n",
       "      <td>0.021526</td>\n",
       "      <td>0.011035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>RF</td>\n",
       "      <td>SMOTE-Sampling</td>\n",
       "      <td>0.673955</td>\n",
       "      <td>0.026544</td>\n",
       "      <td>0.013642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>RL</td>\n",
       "      <td>SMOTE-Sampling</td>\n",
       "      <td>0.274407</td>\n",
       "      <td>0.015262</td>\n",
       "      <td>0.007769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>DT</td>\n",
       "      <td>SMOTE-Sampling</td>\n",
       "      <td>0.504890</td>\n",
       "      <td>0.018015</td>\n",
       "      <td>0.009204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>RF</td>\n",
       "      <td>SMOTE-Sampling</td>\n",
       "      <td>0.557705</td>\n",
       "      <td>0.021373</td>\n",
       "      <td>0.010934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>RL</td>\n",
       "      <td>SMOTE-Sampling</td>\n",
       "      <td>0.128337</td>\n",
       "      <td>0.013113</td>\n",
       "      <td>0.006666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>DT</td>\n",
       "      <td>SMOTE-Sampling</td>\n",
       "      <td>0.391667</td>\n",
       "      <td>0.015248</td>\n",
       "      <td>0.007773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>RF</td>\n",
       "      <td>SMOTE-Sampling</td>\n",
       "      <td>0.351707</td>\n",
       "      <td>0.016262</td>\n",
       "      <td>0.008286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>RL</td>\n",
       "      <td>SMOTE-Sampling</td>\n",
       "      <td>0.024870</td>\n",
       "      <td>0.011930</td>\n",
       "      <td>0.006061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>DT</td>\n",
       "      <td>SMOTE-Sampling</td>\n",
       "      <td>0.233991</td>\n",
       "      <td>0.014102</td>\n",
       "      <td>0.007176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>RF</td>\n",
       "      <td>SMOTE-Sampling</td>\n",
       "      <td>0.119879</td>\n",
       "      <td>0.012829</td>\n",
       "      <td>0.006521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>RL</td>\n",
       "      <td>ADASYN-Sampling</td>\n",
       "      <td>0.572506</td>\n",
       "      <td>0.019077</td>\n",
       "      <td>0.009764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>DT</td>\n",
       "      <td>ADASYN-Sampling</td>\n",
       "      <td>0.983516</td>\n",
       "      <td>0.082888</td>\n",
       "      <td>0.061945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>RF</td>\n",
       "      <td>ADASYN-Sampling</td>\n",
       "      <td>0.992527</td>\n",
       "      <td>0.152589</td>\n",
       "      <td>0.227240</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>84 rows  5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Model           Method       Acc  F1 Score  FBeta Score-b10\n",
       "0     RL   Under-Sampling  0.991422  0.011080         0.017054\n",
       "1     DT   Under-Sampling  0.919913  0.052856         0.028668\n",
       "2     RF   Under-Sampling  0.982771  0.153483         0.108611\n",
       "3     RL   Under-Sampling  0.977942  0.043750         0.029563\n",
       "4     DT   Under-Sampling  0.861715  0.042270         0.022244\n",
       "5     RF   Under-Sampling  0.959440  0.096360         0.055923\n",
       "6     RL   Under-Sampling  0.950117  0.041551         0.023629\n",
       "7     DT   Under-Sampling  0.786962  0.032730         0.016978\n",
       "8     RF   Under-Sampling  0.901410  0.061313         0.032782\n",
       "9     RL   Under-Sampling  0.881563  0.036740         0.019477\n",
       "10    DT   Under-Sampling  0.721436  0.024569         0.012666\n",
       "11    RF   Under-Sampling  0.845592  0.041182         0.021578\n",
       "12    RL   Under-Sampling  0.544177  0.019334         0.009888\n",
       "13    DT   Under-Sampling  0.649134  0.021838         0.011210\n",
       "14    RF   Under-Sampling  0.770358  0.032594         0.016874\n",
       "15    RL   Under-Sampling  0.398034  0.017414         0.008879\n",
       "16    DT   Under-Sampling  0.615542  0.021526         0.011035\n",
       "17    RF   Under-Sampling  0.673955  0.026544         0.013642\n",
       "18    RL   Under-Sampling  0.274407  0.015262         0.007769\n",
       "19    DT   Under-Sampling  0.504890  0.018015         0.009204\n",
       "20    RF   Under-Sampling  0.557705  0.021373         0.010934\n",
       "21    RL   Under-Sampling  0.128337  0.013113         0.006666\n",
       "22    DT   Under-Sampling  0.391667  0.015248         0.007773\n",
       "23    RF   Under-Sampling  0.351707  0.016262         0.008286\n",
       "24    RL   Under-Sampling  0.024870  0.011930         0.006061\n",
       "25    DT   Under-Sampling  0.233991  0.014102         0.007176\n",
       "26    RF   Under-Sampling  0.119879  0.012829         0.006521\n",
       "27    RL    Over-Sampling  0.901294  0.000000         0.000000\n",
       "28    DT    Over-Sampling  0.992887  0.965142         0.934388\n",
       "29    RF    Over-Sampling  0.998195  0.990916         0.983426\n",
       "..   ...              ...       ...       ...              ...\n",
       "54    RL   SMOTE-Sampling  0.991422  0.011080         0.017054\n",
       "55    DT   SMOTE-Sampling  0.919913  0.052856         0.028668\n",
       "56    RF   SMOTE-Sampling  0.982771  0.153483         0.108611\n",
       "57    RL   SMOTE-Sampling  0.977942  0.043750         0.029563\n",
       "58    DT   SMOTE-Sampling  0.861715  0.042270         0.022244\n",
       "59    RF   SMOTE-Sampling  0.959440  0.096360         0.055923\n",
       "60    RL   SMOTE-Sampling  0.950117  0.041551         0.023629\n",
       "61    DT   SMOTE-Sampling  0.786962  0.032730         0.016978\n",
       "62    RF   SMOTE-Sampling  0.901410  0.061313         0.032782\n",
       "63    RL   SMOTE-Sampling  0.881563  0.036740         0.019477\n",
       "64    DT   SMOTE-Sampling  0.721436  0.024569         0.012666\n",
       "65    RF   SMOTE-Sampling  0.845592  0.041182         0.021578\n",
       "66    RL   SMOTE-Sampling  0.544177  0.019334         0.009888\n",
       "67    DT   SMOTE-Sampling  0.649134  0.021838         0.011210\n",
       "68    RF   SMOTE-Sampling  0.770358  0.032594         0.016874\n",
       "69    RL   SMOTE-Sampling  0.398034  0.017414         0.008879\n",
       "70    DT   SMOTE-Sampling  0.615542  0.021526         0.011035\n",
       "71    RF   SMOTE-Sampling  0.673955  0.026544         0.013642\n",
       "72    RL   SMOTE-Sampling  0.274407  0.015262         0.007769\n",
       "73    DT   SMOTE-Sampling  0.504890  0.018015         0.009204\n",
       "74    RF   SMOTE-Sampling  0.557705  0.021373         0.010934\n",
       "75    RL   SMOTE-Sampling  0.128337  0.013113         0.006666\n",
       "76    DT   SMOTE-Sampling  0.391667  0.015248         0.007773\n",
       "77    RF   SMOTE-Sampling  0.351707  0.016262         0.008286\n",
       "78    RL   SMOTE-Sampling  0.024870  0.011930         0.006061\n",
       "79    DT   SMOTE-Sampling  0.233991  0.014102         0.007176\n",
       "80    RF   SMOTE-Sampling  0.119879  0.012829         0.006521\n",
       "81    RL  ADASYN-Sampling  0.572506  0.019077         0.009764\n",
       "82    DT  ADASYN-Sampling  0.983516  0.082888         0.061945\n",
       "83    RF  ADASYN-Sampling  0.992527  0.152589         0.227240\n",
       "\n",
       "[84 rows x 5 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Acc</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>FBeta Score-b10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>84.000000</td>\n",
       "      <td>84.000000</td>\n",
       "      <td>84.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.731584</td>\n",
       "      <td>0.298203</td>\n",
       "      <td>0.296346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.285118</td>\n",
       "      <td>0.414934</td>\n",
       "      <td>0.418476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.024870</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.557705</td>\n",
       "      <td>0.018811</td>\n",
       "      <td>0.009888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.825710</td>\n",
       "      <td>0.041366</td>\n",
       "      <td>0.021911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.985493</td>\n",
       "      <td>0.787629</td>\n",
       "      <td>0.709499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.999836</td>\n",
       "      <td>0.999909</td>\n",
       "      <td>0.999819</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Acc   F1 Score  FBeta Score-b10\n",
       "count  84.000000  84.000000        84.000000\n",
       "mean    0.731584   0.298203         0.296346\n",
       "std     0.285118   0.414934         0.418476\n",
       "min     0.024870   0.000000         0.000000\n",
       "25%     0.557705   0.018811         0.009888\n",
       "50%     0.825710   0.041366         0.021911\n",
       "75%     0.985493   0.787629         0.709499\n",
       "max     0.999836   0.999909         0.999819"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultados.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se puede evidenciar que la media de los modelos calibrados bajo diferentes metodologas es de 0.73 y tanto el F1 Score como el FBeta Score a b=10 no dan valores superior a 1 sino tendenciales a 0. Adicionalmente el percentil 50% muestra que los modelos evaluados tenian un Acc de .82 y aquellos que lograban tener un Acc de .98 lograban casi un F1 y un Beta Score de .78"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
