{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 9\n",
    "\n",
    "## Mashable news stories analysis\n",
    "\n",
    "Predicting if a news story is going to be popular\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>timedelta</th>\n",
       "      <th>n_tokens_title</th>\n",
       "      <th>n_tokens_content</th>\n",
       "      <th>n_unique_tokens</th>\n",
       "      <th>n_non_stop_words</th>\n",
       "      <th>n_non_stop_unique_tokens</th>\n",
       "      <th>num_hrefs</th>\n",
       "      <th>num_self_hrefs</th>\n",
       "      <th>num_imgs</th>\n",
       "      <th>...</th>\n",
       "      <th>min_positive_polarity</th>\n",
       "      <th>max_positive_polarity</th>\n",
       "      <th>avg_negative_polarity</th>\n",
       "      <th>min_negative_polarity</th>\n",
       "      <th>max_negative_polarity</th>\n",
       "      <th>title_subjectivity</th>\n",
       "      <th>title_sentiment_polarity</th>\n",
       "      <th>abs_title_subjectivity</th>\n",
       "      <th>abs_title_sentiment_polarity</th>\n",
       "      <th>Popular</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>http://mashable.com/2014/12/10/cia-torture-rep...</td>\n",
       "      <td>28.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>188.0</td>\n",
       "      <td>0.732620</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.844262</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.80</td>\n",
       "      <td>-0.487500</td>\n",
       "      <td>-0.60</td>\n",
       "      <td>-0.250000</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>http://mashable.com/2013/10/18/bitlock-kicksta...</td>\n",
       "      <td>447.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>297.0</td>\n",
       "      <td>0.653199</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.815789</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.160000</td>\n",
       "      <td>0.50</td>\n",
       "      <td>-0.135340</td>\n",
       "      <td>-0.40</td>\n",
       "      <td>-0.050000</td>\n",
       "      <td>0.1</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>http://mashable.com/2013/07/24/google-glass-po...</td>\n",
       "      <td>533.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.660377</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.775701</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>http://mashable.com/2013/11/21/these-are-the-m...</td>\n",
       "      <td>413.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>781.0</td>\n",
       "      <td>0.497409</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.677350</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>-0.195701</td>\n",
       "      <td>-0.40</td>\n",
       "      <td>-0.071429</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>http://mashable.com/2014/02/11/parking-ticket-...</td>\n",
       "      <td>331.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>177.0</td>\n",
       "      <td>0.685714</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.830357</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.55</td>\n",
       "      <td>-0.175000</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>-0.100000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 url  timedelta  \\\n",
       "0  http://mashable.com/2014/12/10/cia-torture-rep...       28.0   \n",
       "1  http://mashable.com/2013/10/18/bitlock-kicksta...      447.0   \n",
       "2  http://mashable.com/2013/07/24/google-glass-po...      533.0   \n",
       "3  http://mashable.com/2013/11/21/these-are-the-m...      413.0   \n",
       "4  http://mashable.com/2014/02/11/parking-ticket-...      331.0   \n",
       "\n",
       "   n_tokens_title  n_tokens_content  n_unique_tokens  n_non_stop_words  \\\n",
       "0             9.0             188.0         0.732620               1.0   \n",
       "1             7.0             297.0         0.653199               1.0   \n",
       "2            11.0             181.0         0.660377               1.0   \n",
       "3            12.0             781.0         0.497409               1.0   \n",
       "4             8.0             177.0         0.685714               1.0   \n",
       "\n",
       "   n_non_stop_unique_tokens  num_hrefs  num_self_hrefs  num_imgs   ...     \\\n",
       "0                  0.844262        5.0             1.0       1.0   ...      \n",
       "1                  0.815789        9.0             4.0       1.0   ...      \n",
       "2                  0.775701        4.0             3.0       1.0   ...      \n",
       "3                  0.677350       10.0             3.0       1.0   ...      \n",
       "4                  0.830357        3.0             2.0       1.0   ...      \n",
       "\n",
       "   min_positive_polarity  max_positive_polarity  avg_negative_polarity  \\\n",
       "0               0.200000                   0.80              -0.487500   \n",
       "1               0.160000                   0.50              -0.135340   \n",
       "2               0.136364                   1.00               0.000000   \n",
       "3               0.100000                   1.00              -0.195701   \n",
       "4               0.100000                   0.55              -0.175000   \n",
       "\n",
       "   min_negative_polarity  max_negative_polarity  title_subjectivity  \\\n",
       "0                  -0.60              -0.250000                 0.9   \n",
       "1                  -0.40              -0.050000                 0.1   \n",
       "2                   0.00               0.000000                 0.3   \n",
       "3                  -0.40              -0.071429                 0.0   \n",
       "4                  -0.25              -0.100000                 0.0   \n",
       "\n",
       "   title_sentiment_polarity  abs_title_subjectivity  \\\n",
       "0                       0.8                     0.4   \n",
       "1                      -0.1                     0.4   \n",
       "2                       1.0                     0.2   \n",
       "3                       0.0                     0.5   \n",
       "4                       0.0                     0.5   \n",
       "\n",
       "   abs_title_sentiment_polarity  Popular  \n",
       "0                           0.8        1  \n",
       "1                           0.1        0  \n",
       "2                           1.0        0  \n",
       "3                           0.0        0  \n",
       "4                           0.0        0  \n",
       "\n",
       "[5 rows x 61 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "url = 'https://raw.githubusercontent.com/albahnsen/PracticalMachineLearningClass/master/datasets/mashable.csv'\n",
    "train_df = pd.read_csv(url, index_col=0)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6000, 61)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_df.drop(['url', 'Popular'], axis=1)\n",
    "y = train_df['Popular']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train/test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 9.1\n",
    "\n",
    "Estimate a Decision Tree Classifier and a Logistic Regresion\n",
    "\n",
    "Evaluate using the following metrics:\n",
    "* Accuracy\n",
    "* F1-Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Classifier\n",
      "Accuracy\n",
      "0.5446666666666666\n",
      " \n",
      "F1-Score\n",
      "0.5473823724320742\n"
     ]
    }
   ],
   "source": [
    "## Decision Tree Classifier\n",
    "from sklearn.tree import  DecisionTreeClassifier\n",
    "\n",
    "dtc = DecisionTreeClassifier( max_depth=None, random_state=43)\n",
    "dtc.fit(X_train, y_train)\n",
    "y_pred = dtc.predict(X_test)\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "print(\"Decision Tree Classifier\")\n",
    "print(\"Accuracy\")\n",
    "print(str(metrics.accuracy_score(y_pred, y_test)))\n",
    "print(\" \")\n",
    "print(\"F1-Score\")\n",
    "print(str(metrics.f1_score(y_pred, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression\n",
      "Accuracy\n",
      "0.6166666666666667\n",
      " \n",
      "F1-Score\n",
      "0.6026261230131307\n"
     ]
    }
   ],
   "source": [
    "## Logistic Regression\n",
    "\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "lr = LogisticRegressionCV(cv = 5)\n",
    "lr.fit(X_train, y_train)\n",
    "y_pred = lr.predict(X_test)\n",
    "print(\"Logistic Regression\")\n",
    "print(\"Accuracy\")\n",
    "print(str(metrics.accuracy_score(y_pred, y_test)))\n",
    "print(\" \")\n",
    "print(\"F1-Score\")\n",
    "print(str(metrics.f1_score(y_pred, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 9.2\n",
    "\n",
    "Estimate 300 bagged samples\n",
    "\n",
    "Estimate the following set of classifiers:\n",
    "\n",
    "* 100 Decision Trees where max_depth=None\n",
    "* 100 Decision Trees where max_depth=2\n",
    "* 100 Logistic Regressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([ 860, 3772, 3092, ...,  320, 4059, 1131]),\n",
       " array([2578, 4042, 3367, ...,  341,  132,  264]),\n",
       " array([4188, 1685, 1434, ..., 1514, 4297,  633]),\n",
       " array([ 578, 3959,  272, ..., 1340, 3737, 1437]),\n",
       " array([  94, 3296,  948, ..., 2367, 3343, 3097]),\n",
       " array([1260, 1333, 4328, ..., 1082, 4247,  933]),\n",
       " array([2587, 4085,  557, ..., 2116, 2420,   54]),\n",
       " array([  84, 2888, 2779, ..., 1931, 1885, 2353]),\n",
       " array([3807, 2746,  580, ..., 2385, 1286,  925]),\n",
       " array([ 228, 1768, 2421, ...,  183,  837, 1892])]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# set a seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "n_samples = X_train.shape[0]\n",
    "n_B = 300\n",
    "\n",
    "#  300 bagged samples (will be used to select rows from the Train set of the dataframe)\n",
    "samples = [np.random.choice(a=n_samples, size=n_samples, replace=True) for _ in range(1, n_B +1 )]\n",
    "samples[0:10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# grow each tree deep\n",
    "treeclass = DecisionTreeClassifier(max_depth=None, random_state=42)\n",
    "\n",
    "# DataFrame for storing predicted value from each tree\n",
    "y_pred = pd.DataFrame(index=X_test.index, columns=[list(range(n_B))])\n",
    "\n",
    "# grow one tree for each bootstrap sample and make predictions on testing data\n",
    "for i, sample in enumerate(samples):\n",
    "    X_train = X_train.iloc[sample]\n",
    "    y_train = y_train.iloc[sample]\n",
    "    treeclass.fit(X_train, y_train)\n",
    "    y_pred[i] = treeclass.predict(X_test)\n",
    "\n",
    "\n",
    "y_pred2 = (y_pred.sum(axis=1) >= (n_B / 2)).astype(np.int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score\n",
      "0.5699680511182109\n",
      "\n",
      "Accurancy\n",
      "0.5513333333333333\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "print(\"F1-Score\")\n",
    "print(metrics.f1_score(y_pred2, y_test))\n",
    "print()\n",
    "print(\"Accurancy\")\n",
    "print(metrics.accuracy_score(y_pred2, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# grow each tree deep\n",
    "treereg = DecisionTreeClassifier(max_depth=2, random_state=42)\n",
    "\n",
    "# DataFrame for storing predicted value from each tree\n",
    "y_pred_df = pd.DataFrame(index=X_test.index, columns=[list(range(n_B))])\n",
    "\n",
    "# grow one tree for each bootstrap sample and make predictions on testing data\n",
    "for i, sample in enumerate(samples):\n",
    "    X_train = X_train.iloc[sample]\n",
    "    y_train = y_train.iloc[sample]\n",
    "    treereg.fit(X_train, y_train)\n",
    "    y_pred[i] = treereg.predict(X_test)\n",
    "\n",
    "y_pred2 = (y_pred.sum(axis=1) >= (n_B / 2)).astype(np.int)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score\n",
      "0.5994930291508239\n",
      "\n",
      "Accurancy\n",
      "0.5786666666666667\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "print(\"F1-Score\")\n",
    "print(metrics.f1_score(y_pred2, y_test))\n",
    "print()\n",
    "print(\"Accurancy\")\n",
    "print(metrics.accuracy_score(y_pred2, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# grow each tree deep\n",
    "lr = LogisticRegression()\n",
    "\n",
    "# DataFrame for storing predicted value from each tree\n",
    "y_pred_df = pd.DataFrame(index=X_test.index, columns=[list(range(n_B))])\n",
    "\n",
    "# grow one tree for each bootstrap sample and make predictions on testing data\n",
    "for i, sample in enumerate(samples):\n",
    "    X_train = X_train.iloc[sample]\n",
    "    y_train = y_train.iloc[sample]\n",
    "    lr.fit(X_train, y_train)\n",
    "    y_pred[i] = lr.predict(X_test).astype(np.int)\n",
    "    \n",
    "y_pred2 = (y_pred.sum(axis=1) >= (n_B / 2)).astype(np.int)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score\n",
      "0.48852901484480427\n",
      "\n",
      "Accurancy\n",
      "0.49466666666666664\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "print(\"F1-Score\")\n",
    "print(metrics.f1_score(y_pred2, y_test))\n",
    "print()\n",
    "print(\"Accurancy\")\n",
    "print(metrics.accuracy_score(y_pred2, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 9.3\n",
    "\n",
    "Ensemble using majority voting\n",
    "\n",
    "Evaluate using the following metrics:\n",
    "* Accuracy\n",
    "* F1-Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PACHO\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BaggingClassifier with DecisionTreeClassifier and max_depth=2 as estimator \n",
      "Accuracy\n",
      "0.576\n",
      " \n",
      "F1-Score\n",
      "0.4708818635607322\n",
      " \n"
     ]
    }
   ],
   "source": [
    "#  BaggingClassifier to use DecisionTreeClassifier as the \"base estimator\"\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "bagclass= BaggingClassifier(DecisionTreeClassifier(max_depth=2), n_estimators=100,bootstrap=True,\n",
    "                          random_state=42, n_jobs=-1, oob_score=True)\n",
    "bagclass.fit(X_train, y_train)\n",
    "y_pred_DT2 = bagclass.predict(X_test)\n",
    "print(\"BaggingClassifier with DecisionTreeClassifier and max_depth=2 as estimator \")\n",
    "print(\"Accuracy\")\n",
    "print(str(metrics.accuracy_score(y_pred_DT2, y_test)))\n",
    "print(\" \")\n",
    "print(\"F1-Score\")\n",
    "print(str(metrics.f1_score(y_pred_DT2, y_test)))\n",
    "print(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BaggingClassifier with DecisionTreeClassifier as estimator \n",
      "Accuracy\n",
      "0.576\n",
      " \n",
      "F1-Score\n",
      "0.4708818635607322\n",
      " \n"
     ]
    }
   ],
   "source": [
    "bagclass= BaggingClassifier(DecisionTreeClassifier(max_depth=None), n_estimators=100,bootstrap=True,\n",
    "                          random_state=42, n_jobs=-1, oob_score=True)\n",
    "bagclass.fit(X_train, y_train)\n",
    "y_pred_DT0 = bagclass.predict(X_test)\n",
    "print(\"BaggingClassifier with DecisionTreeClassifier as estimator \")\n",
    "print(\"Accuracy\")\n",
    "print(str(metrics.accuracy_score(y_pred_DT0, y_test)))\n",
    "print(\" \")\n",
    "print(\"F1-Score\")\n",
    "print(str(metrics.f1_score(y_pred_DT0, y_test)))\n",
    "print(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BaggingClassifier with Logistic Regression as estimator \n",
      "Accuracy\n",
      "0.498\n",
      " \n",
      "F1-Score\n",
      "0.5212968849332485\n",
      " \n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "bagclass= BaggingClassifier(LogisticRegressionCV(cv = 5), n_estimators=100,bootstrap=True,\n",
    "                          random_state=42, n_jobs=-1, oob_score=True)\n",
    "bagclass.fit(X_train, y_train)\n",
    "y_pred_LR = bagclass.predict(X_test)\n",
    "print(\"BaggingClassifier with Logistic Regression as estimator \")\n",
    "print(\"Accuracy\")\n",
    "print(str(metrics.accuracy_score(y_pred_LR, y_test)))\n",
    "print(\" \")\n",
    "print(\"F1-Score\")\n",
    "print(str(metrics.f1_score(y_pred_LR, y_test)))\n",
    "print(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_ensabled = ((y_pred_DT2+y_pred_DT0+y_pred_LR)/3).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Essambled models metrics\n",
      "Accuracy\n",
      "0.5546666666666666\n",
      "F1-Score\n",
      "0.40674955595026646\n"
     ]
    }
   ],
   "source": [
    "print (\"Essambled models metrics\")\n",
    "print(\"Accuracy\")\n",
    "print(str(metrics.accuracy_score(y_pred_ensabled, y_test)))\n",
    "print(\"F1-Score\")\n",
    "print(str(metrics.f1_score(y_pred_ensabled, y_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bagging regressor models metrics\n",
      "Accuracy\n",
      "0.548\n",
      "F1-Score\n",
      "0.38363636363636366\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "models = {'LR': LogisticRegression(),\n",
    "          'DT0': DecisionTreeClassifier(max_depth=None),\n",
    "          'DT2': DecisionTreeClassifier(max_depth=2)}\n",
    "y_pred_BR = pd.DataFrame (columns =models.keys(),index= y_test.index )\n",
    "for i, model  in models.items():\n",
    "    bagclass = BaggingClassifier(model, n_estimators=100,bootstrap=True, oob_score=True, \n",
    "                                 random_state=42,n_jobs=-1)\n",
    "    bagclass.fit(X_train, y_train)\n",
    "    y_pred_BR[i] = bagclass.predict(X_test)\n",
    "\n",
    "y_pred_BR['predic'] = (y_pred_BR.sum(axis=1)/len(models)).astype(int)\n",
    "print (\"Bagging regressor models metrics\")\n",
    "print(\"Accuracy\")\n",
    "print(str(metrics.accuracy_score(y_pred_BR['predic'] , y_test)))\n",
    "print(\"F1-Score\")\n",
    "print(str(metrics.f1_score(y_pred_BR['predic'] , y_test)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 9.4\n",
    "\n",
    "Estimate te probability as %models that predict positive\n",
    "\n",
    "Modify the probability threshold and select the one that maximizes the F1-Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "th=np.arange(0,1.1,0.1)\n",
    "models = {'LR': LogisticRegression(),\n",
    "          'DT0': DecisionTreeClassifier(max_depth=None),\n",
    "          'DT2': DecisionTreeClassifier(max_depth=2)}\n",
    "Scores_t = []\n",
    "y_pred = pd.DataFrame(index=X_test.index, columns=models.keys())\n",
    "for i in th:\n",
    "    for model in models.keys():\n",
    "        bagreg = BaggingClassifier(models[model], n_estimators=100,bootstrap=True, oob_score=True, random_state=42,n_jobs=-1)\n",
    "        bagreg.fit(X_train, y_train)\n",
    "        y_pred[model] = bagreg.predict_proba(X_test)\n",
    "        y_pred[model] = y_pred[model].apply(lambda x: 1 if x>=i else 0)\n",
    "        Scores_t.append([i,metrics.f1_score(y_test,y_pred[model]),metrics.accuracy_score(y_pred[model], y_test),model])\n",
    "Scores_t=pd.DataFrame(Scores_t, columns=['Threshold','F1-Score','Accuracy','Model'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Threshold</th>\n",
       "      <th>F1-Score</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.670213</td>\n",
       "      <td>0.504000</td>\n",
       "      <td>LR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.670213</td>\n",
       "      <td>0.504000</td>\n",
       "      <td>DT0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.670213</td>\n",
       "      <td>0.504000</td>\n",
       "      <td>DT2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.566565</td>\n",
       "      <td>0.524667</td>\n",
       "      <td>LR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.588409</td>\n",
       "      <td>0.441333</td>\n",
       "      <td>DT0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.588409</td>\n",
       "      <td>0.441333</td>\n",
       "      <td>DT2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.555347</td>\n",
       "      <td>0.526000</td>\n",
       "      <td>LR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.586207</td>\n",
       "      <td>0.440000</td>\n",
       "      <td>DT0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.586207</td>\n",
       "      <td>0.440000</td>\n",
       "      <td>DT2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.3</td>\n",
       "      <td>0.546159</td>\n",
       "      <td>0.531333</td>\n",
       "      <td>LR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.3</td>\n",
       "      <td>0.581546</td>\n",
       "      <td>0.440667</td>\n",
       "      <td>DT0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.3</td>\n",
       "      <td>0.581546</td>\n",
       "      <td>0.440667</td>\n",
       "      <td>DT2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.4</td>\n",
       "      <td>0.527722</td>\n",
       "      <td>0.528667</td>\n",
       "      <td>LR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.4</td>\n",
       "      <td>0.562307</td>\n",
       "      <td>0.433333</td>\n",
       "      <td>DT0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.4</td>\n",
       "      <td>0.562307</td>\n",
       "      <td>0.433333</td>\n",
       "      <td>DT2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.507358</td>\n",
       "      <td>0.531333</td>\n",
       "      <td>LR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.522652</td>\n",
       "      <td>0.424000</td>\n",
       "      <td>DT0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.522652</td>\n",
       "      <td>0.424000</td>\n",
       "      <td>DT2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.6</td>\n",
       "      <td>0.482909</td>\n",
       "      <td>0.526000</td>\n",
       "      <td>LR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.6</td>\n",
       "      <td>0.468523</td>\n",
       "      <td>0.414667</td>\n",
       "      <td>DT0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.6</td>\n",
       "      <td>0.468523</td>\n",
       "      <td>0.414667</td>\n",
       "      <td>DT2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.7</td>\n",
       "      <td>0.456621</td>\n",
       "      <td>0.524000</td>\n",
       "      <td>LR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.7</td>\n",
       "      <td>0.423957</td>\n",
       "      <td>0.429333</td>\n",
       "      <td>DT0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.7</td>\n",
       "      <td>0.423957</td>\n",
       "      <td>0.429333</td>\n",
       "      <td>DT2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.8</td>\n",
       "      <td>0.448249</td>\n",
       "      <td>0.527333</td>\n",
       "      <td>LR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.8</td>\n",
       "      <td>0.358696</td>\n",
       "      <td>0.449333</td>\n",
       "      <td>DT0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.8</td>\n",
       "      <td>0.358696</td>\n",
       "      <td>0.449333</td>\n",
       "      <td>DT2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.9</td>\n",
       "      <td>0.430400</td>\n",
       "      <td>0.525333</td>\n",
       "      <td>LR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.9</td>\n",
       "      <td>0.262418</td>\n",
       "      <td>0.475333</td>\n",
       "      <td>DT0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.9</td>\n",
       "      <td>0.262418</td>\n",
       "      <td>0.475333</td>\n",
       "      <td>DT2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.076543</td>\n",
       "      <td>0.501333</td>\n",
       "      <td>LR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.124153</td>\n",
       "      <td>0.482667</td>\n",
       "      <td>DT0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.124153</td>\n",
       "      <td>0.482667</td>\n",
       "      <td>DT2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Threshold  F1-Score  Accuracy Model\n",
       "0         0.0  0.670213  0.504000    LR\n",
       "1         0.0  0.670213  0.504000   DT0\n",
       "2         0.0  0.670213  0.504000   DT2\n",
       "3         0.1  0.566565  0.524667    LR\n",
       "4         0.1  0.588409  0.441333   DT0\n",
       "5         0.1  0.588409  0.441333   DT2\n",
       "6         0.2  0.555347  0.526000    LR\n",
       "7         0.2  0.586207  0.440000   DT0\n",
       "8         0.2  0.586207  0.440000   DT2\n",
       "9         0.3  0.546159  0.531333    LR\n",
       "10        0.3  0.581546  0.440667   DT0\n",
       "11        0.3  0.581546  0.440667   DT2\n",
       "12        0.4  0.527722  0.528667    LR\n",
       "13        0.4  0.562307  0.433333   DT0\n",
       "14        0.4  0.562307  0.433333   DT2\n",
       "15        0.5  0.507358  0.531333    LR\n",
       "16        0.5  0.522652  0.424000   DT0\n",
       "17        0.5  0.522652  0.424000   DT2\n",
       "18        0.6  0.482909  0.526000    LR\n",
       "19        0.6  0.468523  0.414667   DT0\n",
       "20        0.6  0.468523  0.414667   DT2\n",
       "21        0.7  0.456621  0.524000    LR\n",
       "22        0.7  0.423957  0.429333   DT0\n",
       "23        0.7  0.423957  0.429333   DT2\n",
       "24        0.8  0.448249  0.527333    LR\n",
       "25        0.8  0.358696  0.449333   DT0\n",
       "26        0.8  0.358696  0.449333   DT2\n",
       "27        0.9  0.430400  0.525333    LR\n",
       "28        0.9  0.262418  0.475333   DT0\n",
       "29        0.9  0.262418  0.475333   DT2\n",
       "30        1.0  0.076543  0.501333    LR\n",
       "31        1.0  0.124153  0.482667   DT0\n",
       "32        1.0  0.124153  0.482667   DT2"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Scores_t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 9.5\n",
    "\n",
    "Ensemble using weighted voting using the oob_error\n",
    "\n",
    "Evaluate using the following metrics:\n",
    "* Accuracy\n",
    "* F1-Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {'LR': LogisticRegression(),\n",
    "          'DT0': DecisionTreeClassifier(max_depth=None),\n",
    "          'DT2': DecisionTreeClassifier(max_depth=2)}\n",
    "metrics_t = []\n",
    "mod2={}\n",
    "for model in models.keys():\n",
    "    mod2[model] = BaggingClassifier(models[model], n_estimators=100,bootstrap=True, oob_score=True, random_state=42,n_jobs=-1)\n",
    "    mod2[model].fit(X_train, y_train)\n",
    "    y_pred[model] = mod2[model].predict(X_test)\n",
    "    metrics_t.append([metrics.f1_score(y_pred[model], y_test), metrics.accuracy_score(y_pred[model], y_test),model])\n",
    "metrics_t=pd.DataFrame(metrics_t, columns=['F1-Score','Accurancy','Model'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PACHO\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: RuntimeWarning: invalid value encountered in true_divide\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "C:\\Users\\PACHO\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:11: RuntimeWarning: invalid value encountered in greater_equal\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "C:\\Users\\PACHO\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1137: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best F1 Score:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "F1 Score     0.50889\n",
       "Accurancy      0.466\n",
       "Model             LR\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_t=[]\n",
    "for model in mod2.keys():\n",
    "    errors = np.zeros(mod2[model].n_estimators)\n",
    "    y_pred_all_ = np.zeros((X_test.shape[0], mod2[model].n_estimators))\n",
    "    for i in range(mod2[model].n_estimators):\n",
    "        oob_sample = ~mod2[model].estimators_samples_[i]\n",
    "        y_pred_ = mod2[model].estimators_[i].predict(X_train.values[oob_sample])\n",
    "        errors[i] = metrics.accuracy_score(y_pred_, y_train.values[oob_sample])\n",
    "        y_pred_all_[:, i] = mod2[model].estimators_[i].predict(X_test)\n",
    "    alpha = (1 - errors) / (1 - errors).sum()\n",
    "    y_pred[model] = (np.sum(y_pred_all_ * alpha, axis=1) >= 0.5).astype(np.int)\n",
    "    metrics_t.append([metrics.f1_score(y_pred[model], y_test), metrics.accuracy_score(y_pred[model], y_test),model])\n",
    "\n",
    "metrics_t=pd.DataFrame(metrics_t, columns=['F1 Score','Accurancy','Model'])\n",
    "print('Best F1 Score:')\n",
    "metrics_t.loc[metrics_t['F1 Score'].idxmax()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 9.6\n",
    "\n",
    "Estimate te probability of the weighted voting\n",
    "\n",
    "Modify the probability threshold and select the one that maximizes the F1-Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PACHO\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:12: RuntimeWarning: invalid value encountered in true_divide\n",
      "  if sys.path[0] == '':\n",
      "C:\\Users\\PACHO\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:13: RuntimeWarning: invalid value encountered in greater_equal\n",
      "  del sys.path[0]\n",
      "C:\\Users\\PACHO\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1137: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best F1 Score:\n",
      "Threshold           0\n",
      "F1 Score     0.670213\n",
      "Accurancy       0.504\n",
      "Model              LR\n",
      "Name: 0, dtype: object\n",
      "\n"
     ]
    }
   ],
   "source": [
    "f2=[]\n",
    "th=np.arange(0,1.1,0.1)\n",
    "for j in th:\n",
    "    for model in mod2.keys():\n",
    "        errors = np.zeros(mod2[model].n_estimators)\n",
    "        y_pred_all_ = np.zeros((X_test.shape[0], mod2[model].n_estimators))\n",
    "        for i in range(mod2[model].n_estimators):\n",
    "            oob_sample = ~mod2[model].estimators_samples_[i]\n",
    "            y_pred_ = mod2[model].estimators_[i].predict(X_train.values[oob_sample])\n",
    "            errors[i] = metrics.accuracy_score(y_pred_, y_train.values[oob_sample])\n",
    "            y_pred_all_[:, i] = mod2[model].estimators_[i].predict(X_test)\n",
    "        alpha = (1 - errors) / (1 - errors).sum()\n",
    "        y_pred[model] = (np.sum(y_pred_all_ * alpha, axis=1) >= j).astype(np.int)\n",
    "        f2.append([j, metrics.f1_score(y_pred[model], y_test), metrics.accuracy_score(y_pred[model], y_test),model])\n",
    "f2=pd.DataFrame(f2, columns=['Threshold','F1 Score','Accurancy','Model'])\n",
    "print()\n",
    "print('Best F1 Score:')\n",
    "print(f2.loc[f2['F1 Score'].idxmax()])\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 9.7\n",
    "\n",
    "Estimate a logistic regression using as input the estimated classifiers\n",
    "\n",
    "Modify the probability threshold such that maximizes the F1-Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best F1 Score:\n",
      "Model             DT0\n",
      "F1 Score     0.572966\n",
      "Accurancy    0.576667\n",
      "Name: 1, dtype: object\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ff=[]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n",
    "for model in mod2.keys():\n",
    "    y_pred_all_ = np.zeros((X_test.shape[0], mod2[model].n_estimators))\n",
    "    X_train_logit = np.zeros((X_train.shape[0], mod2[model].n_estimators))\n",
    "    for i in range(mod2[model].n_estimators):\n",
    "        X_train_logit[:, i] = mod2[model].estimators_[i].predict(X_train)\n",
    "        y_pred_all_[:, i] = mod2[model].estimators_[i].predict(X_test)\n",
    "    lr = LogisticRegressionCV(cv=5)\n",
    "    lr.fit(X_train_logit, y_train)\n",
    "    y_pred[model] = lr.predict(y_pred_all_)\n",
    "    ff.append([model, metrics.f1_score(y_pred[model], y_test), metrics.accuracy_score(y_pred[model], y_test)])\n",
    "ff=pd.DataFrame(ff, columns=['Model','F1 Score','Accurancy'])\n",
    "print()\n",
    "print('Best F1 Score:')\n",
    "print(ff.loc[ff['F1 Score'].idxmax()])\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
