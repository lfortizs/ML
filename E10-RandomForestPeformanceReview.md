El paper  publicado en 2014 hace una evaluación de 179 algoritmos de clasificación de 17 familias de clasificadores incluyendo SVM, random forest, árboles de decisión, redes neuronales, boosting, modelos lineales, regresión multinomial y logística, componentes principales,  todos ellos implementados en diferentes plataformas y lenguajes incluyendo R, Weka, C, C++ y Matlab. La evaluación se realiza sobre una colección 121 datasets  en su mayoría del UCI Machine Learning Repository más unos datasets de problemas de la vida real. El uso de una colección de datos variada buscó eliminar los sesgos en los resultados del clasificador sobre un tipo de datos en particular, adicionalmente se usó la misma partición Train y Test sobre cada clasificador. De este ejercicio el autor concluye que el mejor clasificador resulta ser el parallel random forest (parRF_t) implementado en R con caret al ajustar el parámetro mtry. Este algoritmo consigue en promedio 94.1% de la precisión máxima lograda sobre todos los datasets (PAMA por sus siglas en inglés). En segundo lugar se encuentra el random forest en R ajustado con caret, que tiene un rendimiento ligeramente inferior con 93.6%. En tercer lugar se encuentra la implementación LibSVM de Support Vector Machine en C ajustando el spread del kernel. Este logra un 92.3% de la máxima precisión. El autor concluye que estas son las mejores familias de clasificadores al tener seis random forest y cinco SVM dentro del top 20 de los mejores clasificadores. Al final considera que el  parRF_t debería proponerse como un clasificador Golden estándar sobre el cual deberían basarse las comparaciones de rendimiento de nuevos clasificadores propuestos 